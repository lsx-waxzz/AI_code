import torch
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from torch.utils.data import DataLoader
from data_load import WeatherDataset
from model import LSTMWeatherForecast
import matplotlib.dates as mdates
from math import ceil

if __name__ == "__main__":
    # -------------------------- è¯„ä¼°é…ç½®ï¼ˆä¸è®­ç»ƒä¸€è‡´ï¼‰--------------------------
    CSV_PATH = "./data/long_term_forecast/weather/weather.csv"
    LOOK_BACK = 10          # å›çœ‹æ­¥æ•°ï¼ˆå†å²çª—å£ï¼‰
    PREDICT_STEPS = 10      # å•æ¬¡é¢„æµ‹æ­¥æ•°
    BATCH_SIZE = 1          # è¯„ä¼°æ—¶ä½¿ç”¨æ‰¹é‡1ï¼Œä¾¿äºé€æ ·æœ¬å¤„ç†
    MODEL_PATH = "./10step_lstm_single_feature_model.pth"  # æ¨¡å‹è·¯å¾„

    # -------------------------- æ‹†åˆ†ç»˜å›¾é…ç½® --------------------------
    SPLIT_STRATEGY = "time"  # å›ºå®šæŒ‰æ—¶é—´è·¨åº¦æ‹†åˆ†
    TIME_SPAN_DAYS = 10      # æ¯ä¸ªå­å›¾å±•ç¤º10å¤©æ•°æ®
    SUBPLOTS_PER_ROW = 1     # æ¯é¡µ1è¡Œï¼ˆå•å¼ å¤§å›¾æ›´æ¸…æ™°ï¼‰
    SUBPLOTS_PER_COL = 1     # æ¯é¡µ1åˆ— â†’ æ¯é¡µä»…1å¼ 10å¤©çš„å›¾

    # -------------------------- 1. æ•°æ®å‡†å¤‡ï¼ˆä¸¥æ ¼éš”ç¦»æµ‹è¯•é›†ï¼‰--------------------------
    full_df = pd.read_csv(CSV_PATH)
    time_col = next(col for col in full_df.columns if "date" in col.lower())
    full_df[time_col] = pd.to_datetime(full_df[time_col])
    full_df = full_df.sort_values(by=time_col).reset_index(drop=True)
    total_len = len(full_df)

    # ä¸è®­ç»ƒé›†ä¿æŒä¸€è‡´çš„åˆ’åˆ†æ–¹å¼
    train_ratio = 0.8
    train_size_raw = int(total_len * train_ratio)
    test_start = train_size_raw + LOOK_BACK
    if test_start >= total_len:
        test_start = train_size_raw
    
    # è®­ç»ƒé›†ç”¨äºè·å–å½’ä¸€åŒ–å‚æ•°
    train_raw_df = full_df.iloc[:train_size_raw].copy()
    train_dataset = WeatherDataset(
        raw_df=train_raw_df,
        look_back=LOOK_BACK,
        predict_steps=PREDICT_STEPS,
        is_train=True
    )

    # æµ‹è¯•é›†ï¼ˆä¸åŒ…å«è®­ç»ƒæ•°æ®ï¼‰
    test_raw_df = full_df.iloc[test_start - LOOK_BACK:].copy()  # é¢„ç•™LOOK_BACKé•¿åº¦çš„åˆå§‹è¾“å…¥
    test_dataset = WeatherDataset(
        raw_df=test_raw_df,
        look_back=LOOK_BACK,
        predict_steps=PREDICT_STEPS,
        train_min=train_dataset.min_val,
        train_max=train_dataset.max_val,
        is_train=False
    )
    
    if len(test_dataset) == 0:
        print("âŒ æµ‹è¯•é›†æ ·æœ¬æ•°ä¸º0ï¼Œè¯·å¢å¤§æ•°æ®é›†æˆ–è°ƒæ•´LOOK_BACK/PREDICT_STEPS")
        exit(1)
    
    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)

    print("="*60)
    print("ğŸ“Œ æµ‹è¯•é›†ä¿¡æ¯ï¼ˆå•ç‰¹å¾ï¼šä»…æ¸©åº¦ï¼‰")
    print(f"æµ‹è¯•é›†æ—¶é—´èŒƒå›´ï¼š{test_raw_df[time_col].min()} ~ {test_raw_df[time_col].max()}")
    print(f"æµ‹è¯•é›†æ ·æœ¬æ•°ï¼š{len(test_dataset)}")
    print(f"ä½¿ç”¨æ»šåŠ¨é¢„æµ‹ï¼šç”¨å‰é¢çš„é¢„æµ‹å€¼ç»§ç»­é¢„æµ‹åé¢çš„å€¼")
    print(f"ç»˜å›¾ç­–ç•¥ï¼š1) å…¨é‡æµ‹è¯•é›†æ€»è§ˆå›¾ 2) æ¯{TIME_SPAN_DAYS}å¤©ç”Ÿæˆä¸€å¼ æ‹†åˆ†å¯¹æ¯”å›¾")
    print("="*60)

    # -------------------------- 2. åŠ è½½æ¨¡å‹ --------------------------
    model = LSTMWeatherForecast(
        input_size=1,
        hidden_size=32,
        num_layers=2,
        dropout=0.2,
        predict_steps=PREDICT_STEPS
    )
    model.load_state_dict(torch.load(MODEL_PATH))
    model.eval()  # åˆ‡æ¢åˆ°è¯„ä¼°æ¨¡å¼
    print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆï¼š{MODEL_PATH}")

    # -------------------------- 3. æ»šåŠ¨é¢„æµ‹ï¼ˆä¸ä½¿ç”¨æµ‹è¯•é›†çœŸå®æ•°æ®ï¼‰--------------------------
    all_predictions = []
    all_actuals = []
    all_times = []

    with torch.no_grad():  # å…³é—­æ¢¯åº¦è®¡ç®—
        for i, (batch_x, batch_y) in enumerate(test_loader):
            # åˆå§‹è¾“å…¥ï¼šçœŸå®å†å²æ•°æ®
            current_input = batch_x  # shape: [1, LOOK_BACK, 1]
            
            # ä¸€æ¬¡æ€§é¢„æµ‹æœªæ¥PREDICT_STEPSæ­¥ï¼ˆå…¨ç¨‹ä¸ä½¿ç”¨æµ‹è¯•é›†çœŸå®æ•°æ®ï¼‰
            pred = model(current_input)  # shape: [1, PREDICT_STEPS]
            
            # å­˜å‚¨é¢„æµ‹ç»“æœå’ŒçœŸå®å€¼ï¼ˆåå½’ä¸€åŒ–ï¼‰
            pred_denorm = test_dataset.inverse_transform_temp(pred).numpy()[0]
            actual_denorm = test_dataset.inverse_transform_temp(batch_y).numpy()[0]
            
            all_predictions.extend(pred_denorm)
            all_actuals.extend(actual_denorm)
            
            # è®°å½•æ—¶é—´ç‚¹ï¼ˆåŒ¹é…æ•°æ®çš„å®é™…é‡‡æ ·é¢‘ç‡ï¼Œå°æ—¶çº§ï¼‰
            start_time = test_dataset.time_index.iloc[i]
            time_steps = pd.date_range(start=start_time, periods=PREDICT_STEPS, freq='H')  # å°æ—¶çº§é‡‡æ ·
            all_times.extend(time_steps)
            
            # æ‰“å°è¿›åº¦
            if (i + 1) % 10 == 0 or i + 1 == len(test_loader):
                print(f"å·²å®Œæˆ {i + 1}/{len(test_loader)} ä¸ªæµ‹è¯•æ ·æœ¬é¢„æµ‹")

    # å»é‡æ—¶é—´ï¼ˆå¤„ç†æ»šåŠ¨é¢„æµ‹çš„é‡å æ—¶é—´ç‚¹ï¼‰
    results_df = pd.DataFrame({
        'time': all_times,
        'predicted': all_predictions,
        'actual': all_actuals
    }).drop_duplicates(subset='time').sort_values('time').reset_index(drop=True)

    # -------------------------- 4. è®¡ç®—è¯„ä¼°æŒ‡æ ‡ --------------------------
    mse = np.mean((results_df['predicted'] - results_df['actual']) **2)
    mae = np.mean(np.abs(results_df['predicted'] - results_df['actual']))
    rmse = np.sqrt(mse)

    print("\n" + "="*60)
    print("ğŸ“Š é¢„æµ‹è¯„ä¼°æŒ‡æ ‡ï¼ˆå…¨é‡æµ‹è¯•é›†ï¼‰")
    print(f"å‡æ–¹è¯¯å·® (MSE): {mse:.4f}")
    print(f"å‡æ–¹æ ¹è¯¯å·® (RMSE): {rmse:.4f}")
    print(f"å¹³å‡ç»å¯¹è¯¯å·® (MAE): {mae:.4f}")
    print(f"æµ‹è¯•é›†æ•°æ®æ€»é‡ï¼š{len(results_df)} ä¸ªæ—¶é—´ç‚¹")
    print(f"æµ‹è¯•é›†æ€»æ—¶é—´è·¨åº¦ï¼š{(results_df['time'].max() - results_df['time'].min()).days} å¤©")
    print("="*60)

    # -------------------------- 5. ç¬¬ä¸€æ­¥ï¼šç»˜åˆ¶å…¨é‡æµ‹è¯•é›†æ€»è§ˆå›¾ï¼ˆæ‰€æœ‰æ•°æ®åœ¨ä¸€å¼ å›¾ï¼‰--------------------------
    print("\nğŸ¨ å¼€å§‹ç»˜åˆ¶å…¨é‡æµ‹è¯•é›†æ€»è§ˆå›¾...")
    # åˆ›å»ºè¶…å¤§ç”»å¸ƒé€‚é…å…¨é‡æ•°æ®
    fig, ax = plt.subplots(figsize=(40, 12))

    # ç»˜åˆ¶å…¨é‡çœŸå®å€¼å’Œé¢„æµ‹å€¼
    ax.plot(results_df['time'], results_df['actual'], label='çœŸå®æ¸©åº¦', color='blue', linewidth=1.5)
    ax.plot(results_df['time'], results_df['predicted'], label='é¢„æµ‹æ¸©åº¦', color='red', linestyle='--', linewidth=1.5)

    # æ€»è§ˆå›¾æ ‡é¢˜
    total_start_str = results_df['time'].min().strftime("%Y-%m-%d")
    total_end_str = results_df['time'].max().strftime("%Y-%m-%d")
    ax.set_title(
        f'æ¸©åº¦é¢„æµ‹ vs çœŸå®æ¸©åº¦ï¼ˆæ»šåŠ¨é¢„æµ‹ï¼‰- å…¨é‡æµ‹è¯•é›†æ€»è§ˆï¼ˆ{total_start_str} ~ {total_end_str}ï¼‰',
        fontsize=22, pad=25
    )

    # åæ ‡è½´é…ç½®
    ax.set_xlabel('æ—¶é—´', fontsize=18)
    ax.set_ylabel('æ¸©åº¦ (Â°C)', fontsize=18)
    ax.legend(fontsize=16, loc='upper right')
    ax.grid(True, linestyle='--', alpha=0.7)

    # æ ¼å¼åŒ–æ€»è§ˆå›¾æ—¶é—´è½´ï¼ˆæ ¹æ®æ€»è·¨åº¦è‡ªé€‚åº”ï¼‰
    ax.tick_params(axis='x', rotation=45, labelsize=14)
    ax.tick_params(axis='y', labelsize=14)
    total_days = (results_df['time'].max() - results_df['time'].min()).days
    
    # æ€»è·¨åº¦>60å¤© â†’ æŒ‰å‘¨æ˜¾ç¤ºï¼›30-60å¤© â†’ æ¯5å¤©ï¼›<30å¤© â†’ æ¯2å¤©
    if total_days > 60:
        ax.xaxis.set_major_locator(mdates.WeekdayLocator(interval=1))  # æ¯å‘¨
        ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))
    elif total_days > 30:
        ax.xaxis.set_major_locator(mdates.DayLocator(interval=5))      # æ¯5å¤©
        ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))
    else:
        ax.xaxis.set_major_locator(mdates.DayLocator(interval=2))      # æ¯2å¤©
        ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))

    # è°ƒæ•´å¸ƒå±€å¹¶ä¿å­˜æ€»è§ˆå›¾
    plt.tight_layout()
    total_plot_filename = f'temperature_forecast_full_testset_{total_start_str}_{total_end_str}.png'
    plt.savefig(total_plot_filename, dpi=300, bbox_inches='tight')
    print(f"âœ… å…¨é‡æµ‹è¯•é›†æ€»è§ˆå›¾å·²ä¿å­˜ï¼š{total_plot_filename}")
    plt.close()  # é‡Šæ”¾å†…å­˜

    # -------------------------- 6. ç¬¬äºŒæ­¥ï¼šæŒ‰10å¤©æ‹†åˆ†ç»˜åˆ¶ç‹¬ç«‹å›¾ç‰‡ --------------------------
    def split_data_by_10days(df):
        """
        æŒ‰æ¯10å¤©æ‹†åˆ†æ•°æ®ï¼Œè¿”å›æ¯ä¸ª10å¤©æ®µçš„æ•°æ®é›†
        """
        split_dfs = []
        start_time = df['time'].min()
        end_time = df['time'].max()
        current_start = start_time
        
        while current_start < end_time:
            # æ¯æ¬¡å–10å¤©çš„æ—¶é—´èŒƒå›´
            current_end = current_start + pd.Timedelta(days=TIME_SPAN_DAYS)
            # ç­›é€‰å½“å‰10å¤©çš„æ•°æ®
            segment_df = df[(df['time'] >= current_start) & (df['time'] < current_end)].copy()
            if not segment_df.empty:
                split_dfs.append((current_start, current_end, segment_df))
            # æ»‘åŠ¨åˆ°ä¸‹ä¸€ä¸ª10å¤©
            current_start = current_end
        return split_dfs

    # æŒ‰10å¤©æ‹†åˆ†æ•°æ®
    split_segments = split_data_by_10days(results_df)
    print(f"\nğŸ“ æµ‹è¯•é›†å·²æ‹†åˆ†ä¸º {len(split_segments)} ä¸ª10å¤©æ—¶é—´æ®µï¼Œå¼€å§‹ç»˜åˆ¶æ‹†åˆ†å›¾...")

    # é€æ®µç»˜åˆ¶10å¤©ç‹¬ç«‹å›¾ç‰‡
    for seg_idx, (seg_start, seg_end, seg_df) in enumerate(split_segments):
        # åˆ›å»ºç”»å¸ƒï¼ˆé€‚é…10å¤©æ•°æ®çš„å®½é«˜ï¼‰
        fig, ax = plt.subplots(figsize=(25, 10))
        
        # ç»˜åˆ¶å½“å‰10å¤©çš„é¢„æµ‹å€¼å’ŒçœŸå®å€¼
        ax.plot(seg_df['time'], seg_df['actual'], label='çœŸå®æ¸©åº¦', color='blue', linewidth=1.8)
        ax.plot(seg_df['time'], seg_df['predicted'], label='é¢„æµ‹æ¸©åº¦', color='red', linestyle='--', linewidth=1.8)
        
        # å­å›¾æ ‡é¢˜ï¼ˆæ ‡æ³¨10å¤©æ—¶é—´æ®µï¼‰
        seg_start_str = seg_start.strftime("%Y-%m-%d")
        seg_end_str = seg_end.strftime("%Y-%m-%d")
        ax.set_title(
            f'æ¸©åº¦é¢„æµ‹ vs çœŸå®æ¸©åº¦ï¼ˆæ»šåŠ¨é¢„æµ‹ï¼‰- æ—¶é—´æ®µï¼š{seg_start_str} ~ {seg_end_str}ï¼ˆå…±{TIME_SPAN_DAYS}å¤©ï¼‰', 
            fontsize=18, pad=20
        )
        
        # åæ ‡è½´æ ‡ç­¾
        ax.set_xlabel('æ—¶é—´', fontsize=16)
        ax.set_ylabel('æ¸©åº¦ (Â°C)', fontsize=16)
        
        # å›¾ä¾‹
        ax.legend(fontsize=14, loc='upper right')
        
        # ç½‘æ ¼
        ax.grid(True, linestyle='--', alpha=0.7)
        
        # æ ¼å¼åŒ–æ—¶é—´è½´ï¼ˆé€‚é…10å¤©è·¨åº¦ï¼‰
        ax.tick_params(axis='x', rotation=45, labelsize=12)
        ax.tick_params(axis='y', labelsize=12)
        
        # 10å¤©è·¨åº¦ï¼šæŒ‰å¤©æ˜¾ç¤ºåˆ»åº¦ï¼Œæ¯1å¤©/2å¤©ä¸€ä¸ªåˆ»åº¦
        seg_total_days = (seg_end - seg_start).days
        if seg_total_days >= 10:
            ax.xaxis.set_major_locator(mdates.DayLocator(interval=2))  # æ¯2å¤©æ˜¾ç¤ºä¸€ä¸ªåˆ»åº¦
        else:
            ax.xaxis.set_major_locator(mdates.DayLocator(interval=1))  # ä¸è¶³10å¤©åˆ™æŒ‰å¤©æ˜¾ç¤º
        ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))  # ä»…æ˜¾ç¤ºå¹´æœˆæ—¥
        
        # è°ƒæ•´å¸ƒå±€ï¼Œé¿å…æ ‡ç­¾è¢«è£å‰ª
        plt.tight_layout()
        
        # ä¿å­˜å½“å‰10å¤©çš„å›¾ç‰‡ï¼ˆå‘½ååŒ…å«æ—¶é—´æ®µï¼‰
        seg_filename = f'temperature_forecast_10days_{seg_idx+1}_{seg_start_str}_{seg_end_str}.png'
        plt.savefig(seg_filename, dpi=300, bbox_inches='tight')
        print(f"âœ… ç¬¬{seg_idx+1}ä¸ª10å¤©æ—¶é—´æ®µå›¾ç‰‡å·²ä¿å­˜ï¼š{seg_filename}")
        
        # ä¿å­˜å½“å‰10å¤©çš„CSVæ•°æ®
        seg_csv_filename = f'testset_10days_{seg_idx+1}_{seg_start_str}_{seg_end_str}.csv'
        seg_df.to_csv(seg_csv_filename, index=False, encoding='utf-8')
        
        # å…³é—­ç”»å¸ƒé‡Šæ”¾å†…å­˜
        plt.close()

    # -------------------------- 7. ä¿å­˜å…¨é‡æ•°æ®CSV --------------------------
    results_df.to_csv('testset_predictions_vs_actual_full.csv', index=False, encoding='utf-8')
    print(f"\nğŸ“ å…¨é‡é¢„æµ‹ç»“æœå·²ä¿å­˜ä¸ºï¼štestset_predictions_vs_actual_full.csv")
    print(f"\nğŸ‰ ç»˜å›¾å®Œæˆï¼ç”Ÿæˆæ–‡ä»¶æ¸…å•ï¼š")
    print(f"  1. å…¨é‡æ€»è§ˆå›¾ï¼š{total_plot_filename}")
    print(f"  2. {len(split_segments)} å¼ 10å¤©æ‹†åˆ†å¯¹æ¯”å›¾ï¼ˆæ–‡ä»¶åå«10daysæ ‡è¯†ï¼‰")
    print(f"  3. å…¨é‡æ•°æ®CSV + {len(split_segments)} ä¸ª10å¤©åˆ†æ®µCSV")
